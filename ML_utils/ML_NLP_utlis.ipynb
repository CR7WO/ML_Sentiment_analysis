{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "from opencc import OpenCC\n",
    "from gensim.models import word2vec\n",
    "import logging\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def jieba_string_segmentation(string,delimiter=' ',stopword_path=None,split=False,encoding='utf-8'):\n",
    "    \"\"\"\n",
    "    split: string to list\n",
    "    stopword_path: delimiter of stopword must is '\\n'\n",
    "    \"\"\"\n",
    "    # jieba custom setting.\n",
    "    jieba.set_dictionary('jieba_dict/dict.txt.big')\n",
    "    # load stopwords set\n",
    "    #將停用詞每row分別加進集合\n",
    "    stopword_set = set()\n",
    "    if stopword_path != None:\n",
    "        #設置停用詞讀取路徑\n",
    "        with open(stopword_path,'r', encoding=encoding) as stopwords:\n",
    "            for stopword in stopwords:\n",
    "                stopword_set.add(stopword.strip('\\n'))   #移除頭尾換行 strip('\\n')\n",
    "    output = ''\n",
    "    string = string.strip('\\n')\n",
    "    words = jieba.cut(string, cut_all=False,HMM=True)    #進行斷詞\n",
    "    for word in words:\n",
    "        #依每個詞判斷是否為停用詞(不是就寫入)\n",
    "        if word not in stopword_set:\n",
    "            output = output+word+delimiter\n",
    "    if split == True:\n",
    "        output = output.split(delimiter)\n",
    "    return output\n",
    "\n",
    "def str_to_opencc(string,conversion='s2t'):\n",
    "    \"\"\"\n",
    "    opencc:\n",
    "    https://github.com/yichen0831/opencc-python\n",
    "    conversion: \n",
    "    hk2s: Traditional Chinese (Hong Kong standard) to Simplified Chinese\n",
    "    s2hk: Simplified Chinese to Traditional Chinese (Hong Kong standard)\n",
    "    s2t: Simplified Chinese to Traditional Chinese\n",
    "    s2tw: Simplified Chinese to Traditional Chinese (Taiwan standard)\n",
    "    s2twp: Simplified Chinese to Traditional Chinese (Taiwan standard, with phrases)\n",
    "    t2hk: Traditional Chinese to Traditional Chinese (Hong Kong standard)\n",
    "    t2s: Traditional Chinese to Simplified Chinese\n",
    "    t2tw: Traditional Chinese to Traditional Chinese (Taiwan standard)\n",
    "    tw2s: Traditional Chinese (Taiwan standard) to Simplified Chinese\n",
    "    tw2sp: Traditional Chinese (Taiwan standard) to Simplified Chinese (with phrases)\n",
    "    \"\"\"\n",
    "    cc = OpenCC(conversion)\n",
    "    out =  cc.convert(string)\n",
    "    return out\n",
    "\n",
    "def jieba_file_segmentation(file_path,save_path,replace_old=False,word_delimiter=' ',\n",
    "                            file_delimiter='\\n',stopword_path=None,encoding='utf-8'):\n",
    "    \"\"\"\n",
    "    batch using dir_file_call_function()\n",
    "    close log using \"logging.disable(lvl)\"\n",
    "    https://docs.python.org/3/library/logging.html\n",
    "    stopword_path: delimiter of stopword must is '\\n'\n",
    "    \"\"\"\n",
    "    #設置log格式，以及print的log等級\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    # jieba custom setting.\n",
    "    jieba.set_dictionary('jieba_dict/dict.txt.big')\n",
    "    #將停用詞每row分別加進集合\n",
    "    stopword_set = set()\n",
    "    if stopword_path != None:\n",
    "        with open(stopword_path,'r', encoding=encoding) as stopwords:\n",
    "            for stopword in stopwords:\n",
    "                stopword_set.add(stopword.strip('\\n'))   #移除頭尾換行 strip('\\n')\n",
    "    #open write file\n",
    "    output = open(save_path, 'w', encoding=encoding)\n",
    "    with open(file_path, 'r', encoding=encoding) as content :\n",
    "        #每一行都切成一個iter\n",
    "        for texts_num, line in enumerate(content):\n",
    "            line = line.strip('\\n')\n",
    "            words = jieba.cut(line, cut_all=False,HMM=True)    #進行斷詞\n",
    "            for word in words:\n",
    "                #依每個詞判斷是否為停用詞(不是就寫入)\n",
    "                if word not in stopword_set:\n",
    "                    output.write(word + word_delimiter)     #每一行的iter(詞)以空格隔開\n",
    "            output.write(file_delimiter)      #iter完以換行符區隔\n",
    "            if (texts_num + 1) % 10000 == 0:\n",
    "                logging.info(\"已完成前 %d 行的斷詞\" % (texts_num + 1))\n",
    "    output.close()\n",
    "    if replace_old == True:\n",
    "        shutil.move(save_path,file_path)\n",
    "\n",
    "def file_to_opencc(file_path,save_path,replace_old=False,conversion='s2t',encoding='utf-8'):\n",
    "    \"\"\"\n",
    "    batch using dir_file_call_function()\n",
    "    close log using \"logging.disable(lvl)\"\n",
    "    https://docs.python.org/3/library/logging.html\n",
    "    opencc:\n",
    "    https://github.com/yichen0831/opencc-python\n",
    "    conversion: \n",
    "    hk2s: Traditional Chinese (Hong Kong standard) to Simplified Chinese\n",
    "    s2hk: Simplified Chinese to Traditional Chinese (Hong Kong standard)\n",
    "    s2t: Simplified Chinese to Traditional Chinese\n",
    "    s2tw: Simplified Chinese to Traditional Chinese (Taiwan standard)\n",
    "    s2twp: Simplified Chinese to Traditional Chinese (Taiwan standard, with phrases)\n",
    "    t2hk: Traditional Chinese to Traditional Chinese (Hong Kong standard)\n",
    "    t2s: Traditional Chinese to Simplified Chinese\n",
    "    t2tw: Traditional Chinese to Traditional Chinese (Taiwan standard)\n",
    "    tw2s: Traditional Chinese (Taiwan standard) to Simplified Chinese\n",
    "    tw2sp: Traditional Chinese (Taiwan standard) to Simplified Chinese (with phrases)\n",
    "    \"\"\"\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    cc = OpenCC(conversion)\n",
    "    string = ''\n",
    "    with open(file_path,'r',encoding=encoding) as read_f:\n",
    "        with open(save_path,'w',encoding=encoding) as write_f:\n",
    "            for texts_num,read_line in enumerate(read_f):\n",
    "                file_str =  cc.convert(read_line)\n",
    "                write_f.writelines(file_str)\n",
    "                if (texts_num + 1) % 10000 == 0:\n",
    "                    logging.info(\"已完成前 %d 行的轉換\" % (texts_num + 1))\n",
    "    if replace_old == True:\n",
    "        shutil.move(save_path,file_path)\n",
    "        \n",
    "def word2vec_train(file_path,save_path,dir_path=None,save_name='word2vec_model',replace_old=False,\n",
    "                   model_size=300,model_window=10,model_min_count=5,**kw):\n",
    "    \"\"\"\n",
    "    batch train usage: set dir_path、save_name, file_path = None, save_path = None\n",
    "    if Multiple files using dir_path\n",
    "    \"\"\"\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    # https://radimrehurek.com/gensim/models/word2vec.html\n",
    "    if file_path != None:\n",
    "        #單檔案\n",
    "        sentences = word2vec.LineSentence(file_path)\n",
    "        model = word2vec.Word2Vec(sentences, size=model_size,window=model_window,min_count=model_min_count,**kw)\n",
    "        #保存模型，供日後使用\n",
    "        model.save(save_path)\n",
    "    if dir_path != None and file_path == None:\n",
    "        #多檔案\n",
    "        sentences = word2vec.PathLineSentences(dir_path)\n",
    "        model = word2vec.Word2Vec(sentences, size=model_size,window=model_window,min_count=model_min_count,**kw)\n",
    "        #保存模型，供日後使用\n",
    "        model.save(os.path.join(dir_path,save_name))\n",
    "    #模型讀取方式\n",
    "    # model = word2vec.Word2Vec.load(\"your_model_name\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

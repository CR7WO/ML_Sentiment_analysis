{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ML_utils import ML_utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = r'D:\\Backup\\ml_data\\GitHub\\ML_Sentiment_analysis\\Dataset'\n",
    "x = ML_utils.CallF_DirFile(dir_path,ML_utils.WordToList_file,max_word_num=60,padding=0,file_filter_='sentiment')[0]\n",
    "y = np.concatenate( (np.full(1000,0),np.full(1000,1)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self,x,y,model_path,transform=None,target_transform=None,seq_len=30):\n",
    "        \"\"\"\n",
    "        seq_len: Trim length to seq_len\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        file_path = file_path\n",
    "        self.chat_data = self.trim(file_path,max_word_num=seq_len)\n",
    "        self.word_vec_path = model_path\n",
    "        self.word_vec_model = word2vec.Word2Vec.load(self.word_vec_path)\n",
    "        #padding(Null / other)\n",
    "        self.padding = np.zeros((1,300),dtype=np.float32)\n",
    "#         self.padding = np.array(self.word_vec_model.wv.get_vector('。')).reshape(1,300)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        X,Y = self.word_to_vec(index)\n",
    "        return X, Y\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.chat_data)\n",
    "    \n",
    "    def trim(self,file_path,max_word_num):\n",
    "        with open(file_path,'r',encoding='utf-8') as f:\n",
    "            new_list = []\n",
    "            for chat in f:\n",
    "                #依行讀取\n",
    "                save_chat = chat.strip('\\n').split('\\t')\n",
    "                X = save_chat[0].split(' ')\n",
    "                Y = save_chat[1].split(' ')\n",
    "                #如果詞數大於max_word_num\n",
    "                if len(X) < max_word_num and len(Y) < max_word_num:\n",
    "                    for num in range(max_word_num-len(X)):\n",
    "                        X.append(0)\n",
    "                    for num in range(max_word_num-len(Y)):\n",
    "                        Y.append(0)\n",
    "                    new_list.append([X,Y])\n",
    "                if len(save_chat) < 2:\n",
    "                    print(save_chat)\n",
    "                    break\n",
    "            num = len(new_list)//100\n",
    "            new_list = new_list[:num*100]\n",
    "        return new_list\n",
    "    \n",
    "    def word_to_vec(self,index):\n",
    "        chat = self.chat_data[index]\n",
    "        #X\n",
    "        vec_array = np.zeros((1,300),dtype=np.float32)\n",
    "        for word in chat[0]:\n",
    "            if word == 0:\n",
    "                vec = self.padding\n",
    "                vec_array = np.concatenate((vec_array,vec),axis=0)\n",
    "            else:\n",
    "                try:\n",
    "                    vec = np.array(self.word_vec_model.wv.get_vector(word),np.float32).reshape(1,300)\n",
    "                    vec_array = np.concatenate((vec_array,vec),axis=0)\n",
    "                except KeyError:\n",
    "                    vec = self.padding\n",
    "                    vec_array = np.concatenate((vec_array,vec),axis=0)\n",
    "        X = vec_array[1:]\n",
    "        #Y\n",
    "        vec_array = np.zeros((1,300),dtype=np.float32)\n",
    "        for word in chat[1]:\n",
    "            if word == 0:\n",
    "                vec = self.padding\n",
    "                vec_array = np.concatenate((vec_array,vec),axis=0)\n",
    "            else:\n",
    "                try:\n",
    "                    vec = np.array(self.word_vec_model.wv.get_vector(word),np.float32).reshape(1,300)\n",
    "                    vec_array = np.concatenate((vec_array,vec),axis=0)\n",
    "                except KeyError:\n",
    "                    vec = self.padding\n",
    "                    vec_array = np.concatenate((vec_array,vec),axis=0)\n",
    "        Y = vec_array[1:]\n",
    "        return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 60"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
